<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>reinforcement learning | Rodrigo Lira</title>
    <link>https://rodrigoclira.github.io/tag/reinforcement-learning/</link>
      <atom:link href="https://rodrigoclira.github.io/tag/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>reinforcement learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>pt</language><copyright>Rodrigo Lira · 2024</copyright><lastBuildDate>Fri, 15 Nov 2024 17:15:00 +0000</lastBuildDate>
    <image>
      <url>https://rodrigoclira.github.io/media/icon_huf2b89bb3aeddaf27bedd36282c847631_693_512x512_fill_lanczos_center_3.png</url>
      <title>reinforcement learning</title>
      <link>https://rodrigoclira.github.io/tag/reinforcement-learning/</link>
    </image>
    
    <item>
      <title>Exploring Social Dynamics in a Reinforcement Learning-based Metaheuristic: A study using Improvement Frequency and Population Turnover</title>
      <link>https://rodrigoclira.github.io/talk/exploring-social-dynamics-in-a-reinforcement-learning-based-metaheuristic-a-study-using-improvement-frequency-and-population-turnover/</link>
      <pubDate>Fri, 15 Nov 2024 17:15:00 +0000</pubDate>
      <guid>https://rodrigoclira.github.io/talk/exploring-social-dynamics-in-a-reinforcement-learning-based-metaheuristic-a-study-using-improvement-frequency-and-population-turnover/</guid>
      <description>&lt;div class=&#34;responsive-wrap&#34;&gt;
  &lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vT_cTBglurlzIJaP7_OeSmOFE_iR8FeDP_a-jUe5jALFGlF0A4uXTabRO7P9RVuCb3G8sYJycMwSR4T/embed?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Applying Reinforcement Learning to Combine Multiple Swarm-based Algorithms</title>
      <link>https://rodrigoclira.github.io/talk/applying-reinforcement-learning-to-combine-multiple-swarm-based-algorithms/</link>
      <pubDate>Tue, 31 Oct 2023 17:15:00 +0000</pubDate>
      <guid>https://rodrigoclira.github.io/talk/applying-reinforcement-learning-to-combine-multiple-swarm-based-algorithms/</guid>
      <description>&lt;div class=&#34;responsive-wrap&#34;&gt;
  &lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vSbE4VhbB5g93wNH0O3sH2z4U0AzwgXBQcgEPX8o_UlcvEqp1Pf-F25F18PyTsObzfXjsS2_wYEF0wi/embed?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Applying Reinforcement Learning for Multiple Functions in Swarm Intelligence</title>
      <link>https://rodrigoclira.github.io/talk/applying-reinforcement-learning-for-multiple-functions-in-swarm-intelligence/</link>
      <pubDate>Wed, 27 Sep 2023 17:15:00 +0000</pubDate>
      <guid>https://rodrigoclira.github.io/talk/applying-reinforcement-learning-for-multiple-functions-in-swarm-intelligence/</guid>
      <description>&lt;div class=&#34;responsive-wrap&#34;&gt;
  &lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vTpPPjfMMDMwKfvTdcdDvUla1c0hghKYRYbZb46VSu_onSE6OeoRt9U7eENOs06CLwll5TwNrUf4GuF/embed?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Integrating Reinforcement Learning and Optimization Task - Evaluating an Agent to Dynamically Select PSO Communication Topology</title>
      <link>https://rodrigoclira.github.io/talk/integrating-reinforcement-learning-and-optimization-task-evaluating-an-agent-to-dynamically-select-pso-communication-topology/</link>
      <pubDate>Sat, 15 Jul 2023 11:10:00 +0000</pubDate>
      <guid>https://rodrigoclira.github.io/talk/integrating-reinforcement-learning-and-optimization-task-evaluating-an-agent-to-dynamically-select-pso-communication-topology/</guid>
      <description>&lt;div class=&#34;responsive-wrap&#34;&gt;
  &lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vSppxUfx6PQqeXumrVvYYhzJPPBOtbJjcZmQHJwYl3HHR-yDTX6YKXIYfd9Z6AK2LJhl2oKBjqAn7U_/embed?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Material sobre Reinforcement Learning</title>
      <link>https://rodrigoclira.github.io/post/2023/rl-material/</link>
      <pubDate>Thu, 22 Jun 2023 10:18:25 -0300</pubDate>
      <guid>https://rodrigoclira.github.io/post/2023/rl-material/</guid>
      <description>&lt;p&gt;Eu estou usando Aprendizam Por Reforço (do inglês, Reinforcement Learning) na minha tese de doutorado e no processo de aprendizado eu acabei encontrando muitos materias interessantes na internet. Resolvi fazer uma listagem deles para deixar público e também me ajudar em consultas futuras.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Para quem estiver procurando conhecimento teórico, eu sugiro os livros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://incompleteideas.net/book/RLbook2020.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Reinforcement Learning: An Introduction&lt;/a&gt; de Sutton e Barto&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sites.ualberta.ca/~szepesva/rlbook.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Algorithms of Reinforcement Learning&lt;/a&gt; de Szepesvari&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Para quem quiser conhecer um pouco da teoria ao mesmo tempo que desenvolve projetos práticos com Python:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/learn/deep-rl-course/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep RL Course&lt;/a&gt; do Hugginfaces&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://applied-rl-course.netlify.app/en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Applied Reinforcement Learning&lt;/a&gt; com RLLib&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://courses.dibya.online/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Real World Deep RL*&lt;/a&gt; do Dibya.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://spinningup.openai.com/en/latest/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open AI Spinning up in Deep RL&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;* Há também o curso &lt;a href=&#34;https://courses.dibya.online/p/fastdeeprl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fast RL&lt;/a&gt; que eu não realizei.&lt;/p&gt;
&lt;p&gt;Disciplinas em instituições:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rail.eecs.berkeley.edu/deeprlcourse/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CS 285 @ UC Berkeley&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/cs234/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CS234 @ Stanford&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLqYmG7hTraZDVH599EItlEWsUOsJbAodm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RL Lecture Series @ DeepMind and UCL &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to Reinfocement Learning with David Silver @ Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Inteligência de enxames com aprendizado de máquina por reforço para resolução de problemas de otimização</title>
      <link>https://rodrigoclira.github.io/project/rl-mh/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://rodrigoclira.github.io/project/rl-mh/</guid>
      <description>&lt;p&gt;Inteligência de enxames é uma subárea de computação inteligente que compreende abordagens que se inspiram no comportamento inteligente emergente da interação entre seres vivos para resolução de problemas complexos. Ao longo das últimas três décadas, muitas foram as propostas que surgiram na área, as quais são baseadas nas mais diversas metáforas. Uma característica em comum a essas propostas é que os agentes costumam seguir em todo o processo de resolução do problema a inspiração utilizada na sua concepção. Sabendo-se que existem diversos problemas de otimização e que mesmo em um único problema existem fases que precisam de diferentes comportamentos, seguir um conjunto de operadores bem definido por um algoritmo é um fator limitante. Por esse motivo, este projeto visa desenvolver uma meta-heurística adaptativa para resolução de problemas de otimização que consiga se auto-organizar no exame (ou sub-enxames) mais promissor de acordo com informações obtidas &lt;em&gt;on-line&lt;/em&gt; na execução.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
